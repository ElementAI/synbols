{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 302.04it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d04fca6768e4a57b215eedb406790eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select exp_group', layout=Layout(width='200px')), HBox(children=(Dropdown(layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require.config({\n",
       "            paths: {\n",
       "                DT: '//cdn.datatables.net/1.10.19/js/jquery.dataTables.min',\n",
       "            }\n",
       "        });\n",
       "        $('head').append('<link rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\">');\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c9ceb0abc24f1baff331276193d419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .output_scroll {\n",
       "                height: unset !important;\n",
       "                border-radius: unset !important;\n",
       "                -webkit-box-shadow: unset !important;\n",
       "                box-shadow: unset !important;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify variables\n",
    "# sys.path.insert(local_haven)\n",
    "from haven import haven_jupyter as hj\n",
    "from haven import haven_results as hr\n",
    "from haven import haven_utils as hu\n",
    "\n",
    "# please define the path to the experiments\n",
    "savedir_base = '/mnt/projects/vision_prototypes/synbols/logs_borgy_baselines_adam_hdf5_tiny/'\n",
    "# savedir_base = '/mnt/projects/vision_prototypes/synbols/font_plain_borgy/'\n",
    "\n",
    "exp_list = None\n",
    "\n",
    "# exp_config_name = <exp_config_name>\n",
    "# exp_list = hu.load_py(exp_config_name).EXP_GROUPS['mnist']\n",
    "\n",
    "# get specific experiments, for example, {'model':'resnet34'}\n",
    "filterby_list = None\n",
    "\n",
    "# group the experiments based on a hyperparameter, for example, ['dataset']\n",
    "groupby_list = None\n",
    "verbose = 0\n",
    "\n",
    "# plot vars\n",
    "# y_metrics='train_loss'\n",
    "x_metric='epoch'\n",
    "# log_metric_list = ['train_loss']\n",
    "map_exp_list = []\n",
    "# title_list=['dataset']\n",
    "# legend_list=['model']\n",
    "\n",
    "# get experiments\n",
    "rm = hr.ResultManager(exp_list=exp_list, \n",
    "                      savedir_base=savedir_base, \n",
    "                      filterby_list=filterby_list,\n",
    "                      verbose=verbose\n",
    "                     )\n",
    "score_lists = rm.get_score_lists()\n",
    "# score = rm.get_score_table(columns=['dataset', 'exp_id'])\n",
    "\n",
    "\n",
    "# launch dashboard\n",
    "hj.get_dashboard(rm, vars(), wide_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "exp_list = rm.get_exp_list_df()\n",
    "\n",
    "def get_hyperparameters(exp_list_df, min_threshold=2, max_threshold=None):\n",
    "    exp_list_df.reset_index()\n",
    "    if max_threshold is None:\n",
    "        max_threshold = exp_list.shape[0] - 1\n",
    "    column_count = []\n",
    "    for column in exp_list.columns:\n",
    "        _set = set([str(v) for v in exp_list[column].values])\n",
    "        column_count.append(len(_set))\n",
    "    indices = np.arange(len(exp_list.columns))\n",
    "    column_count = np.array(column_count)\n",
    "    indices = indices[(column_count >= min_threshold) & (column_count <= max_threshold)]\n",
    "    hyperparameters = [exp_list.columns[i] for i in indices]\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multipage(filename, figs=None, dpi=200):\n",
    "    pp = PdfPages(filename)\n",
    "    if figs is None:\n",
    "        figs = [plt.figure(n) for n in plt.get_fignums()]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "multipage('synbols.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dset:tiny, Task:font, OOD:True\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Dset:tiny, Task:font, OOD:False\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Dset:tiny, Task:char, OOD:True\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Dset:tiny, Task:char, OOD:False\n",
      "0.6555\n",
      "0.7565\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df = rm.get_score_df()\n",
    "datasets = [\"plain\", \"default_n=1000000_\", \"default_n=100000_\", \"mnist\", \"svhn\", \"camouflage\", \"tiny\"]\n",
    "datasets = ['tiny']\n",
    "models = [\"mlp\", \"conv4\", \"resnet18\", \"resnet50\", \"vgg16\", \"warn\"]\n",
    "tasks = [\"font\", \"char\"]\n",
    "ood = [True, False]\n",
    "\n",
    "\n",
    "def filter_dataset(dataframe, dset):\n",
    "    if dataset in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.name\"].str.contains(dset)]\n",
    "    else:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.path\"].str.contains(dset)]\n",
    "    return df_dataset\n",
    "def filter_task(dataframe, task):\n",
    "    if dataset not in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.task\"].str.contains(task)]\n",
    "    else:\n",
    "        df_dataset = dataframe\n",
    "    return df_dataset \n",
    "def filter_ood(dataframe, ood):\n",
    "    if ood:\n",
    "        df_ood = dataframe[dataframe['dataset.ood'] == True]\n",
    "    else:\n",
    "        df_ood = dataframe\n",
    "    \n",
    "    return df_ood\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    #     df_model = df[df[\"backbone.name\"].str.contains(model)]\n",
    "    df_dataset = filter_dataset(df, dataset)\n",
    "    for task in tasks:\n",
    "        df_task = filter_task(df_dataset, task)\n",
    "        for ood in [True, False]:\n",
    "            print(\"Dset:%s, Task:%s, OOD:%s\"% (dataset, task, ood))\n",
    "            df_ood = filter_ood(df_task, ood)\n",
    "#             df_ood = df_task\n",
    "            for model in models:\n",
    "                df_model = df_ood[df_ood[\"backbone.name\"].str.contains(model)]\n",
    "                print(df_model[\"val_accuracy (max)\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny\n",
      "0.0018573602040608723\n",
      "0.0030656655629475913\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df = rm.get_score_df()\n",
    "\n",
    "datasets = [\"plain\", \"default_n=1000000_\", \"default_n=100000_\", \"mnist\", \"svhn\", \"tiny\"]\n",
    "datasets = [\"tiny\"]\n",
    "models = [\"mlp\", \"conv4\", \"resnet18\", \"resnet50\", \"vgg16\", \"warn\"]\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "#     df_model = df[df[\"backbone.name\"].str.contains(model)]\n",
    "    print(dataset)\n",
    "    if dataset in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = df[df[\"dataset.name\"].str.contains(dataset)]\n",
    "    else:\n",
    "        df_dataset = df[df[\"dataset.path\"].str.contains(dataset)]\n",
    "    for model in models:\n",
    "        df_model = df_dataset[df_dataset[\"backbone.name\"].str.contains(model)]\n",
    "        print(df_model[\"val_batch_time\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
