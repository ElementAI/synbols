{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 401.93it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b61565834044bca2754e97289a0301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select exp_group', layout=Layout(width='200px')), HBox(children=(Dropdown(layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require.config({\n",
       "            paths: {\n",
       "                DT: '//cdn.datatables.net/1.10.19/js/jquery.dataTables.min',\n",
       "            }\n",
       "        });\n",
       "        $('head').append('<link rel=\"stylesheet\" type=\"text/css\" href=\"//cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\">');\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da0895be50e42fcbe8f98fa0601628d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .output_scroll {\n",
       "                height: unset !important;\n",
       "                border-radius: unset !important;\n",
       "                -webkit-box-shadow: unset !important;\n",
       "                box-shadow: unset !important;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "# Specify variables\n",
    "# sys.path.insert(local_haven)\n",
    "from haven import haven_jupyter as hj\n",
    "from haven import haven_results as hr\n",
    "from haven import haven_utils as hu\n",
    "\n",
    "# please define the path to the experiments\n",
    "savedir_base = '/mnt/projects/vision_prototypes/synbols/white_noise_borgy/'\n",
    "# savedir_base = '/mnt/projects/vision_prototypes/synbols/logs_borgy_baselines/'\n",
    "# savedir_base = '/mnt/projects/vision_prototypes/synbols/font_plain_borgy/'\n",
    "\n",
    "exp_list = None\n",
    "\n",
    "# exp_config_name = <exp_config_name>\n",
    "# exp_list = hu.load_py(exp_config_name).EXP_GROUPS['mnist']\n",
    "\n",
    "# get specific experiments, for example, {'model':'resnet34'}\n",
    "filterby_list = None\n",
    "\n",
    "# group the experiments based on a hyperparameter, for example, ['dataset']\n",
    "groupby_list = None\n",
    "verbose = 0\n",
    "\n",
    "# plot vars\n",
    "# y_metrics='train_loss'\n",
    "x_metric='epoch'\n",
    "# log_metric_list = ['train_loss']\n",
    "map_exp_list = []\n",
    "# title_list=['dataset']\n",
    "# legend_list=['model']\n",
    "\n",
    "# get experiments\n",
    "rm = hr.ResultManager(exp_list=exp_list, \n",
    "                      savedir_base=savedir_base, \n",
    "                      filterby_list=filterby_list,\n",
    "                      verbose=verbose\n",
    "                     )\n",
    "score_lists = rm.get_score_lists()\n",
    "# score = rm.get_score_table(columns=['dataset', 'exp_id'])\n",
    "\n",
    "\n",
    "# launch dashboard\n",
    "hj.get_dashboard(rm, vars(), wide_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "exp_list = rm.get_exp_list_df()\n",
    "\n",
    "def get_hyperparameters(exp_list_df, min_threshold=2, max_threshold=None):\n",
    "    exp_list_df.reset_index()\n",
    "    if max_threshold is None:\n",
    "        max_threshold = exp_list.shape[0] - 1\n",
    "    column_count = []\n",
    "    for column in exp_list.columns:\n",
    "        _set = set([str(v) for v in exp_list[column].values])\n",
    "        column_count.append(len(_set))\n",
    "    indices = np.arange(len(exp_list.columns))\n",
    "    column_count = np.array(column_count)\n",
    "    indices = indices[(column_count >= min_threshold) & (column_count <= max_threshold)]\n",
    "    hyperparameters = [exp_list.columns[i] for i in indices]\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multipage(filename, figs=None, dpi=200):\n",
    "    pp = PdfPages(filename)\n",
    "    if figs is None:\n",
    "        figs = [plt.figure(n) for n in plt.get_fignums()]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "multipage('synbols.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dset:mnist, Task:char, MASK:'random'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: train_accuracy (max)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-26d1d706ecff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mdf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ood\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_ood\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"backbone.name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mdf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_accuracy (max)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.02f ±%.02f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_accuracy (max)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_accuracy (max)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, df_model[\"val_accuracy (max)\"].std())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m             )\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: train_accuracy (max)'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = rm.get_score_df()\n",
    "datasets = [\"mnist\", \"svhn\", \"default_n=100000_\",\"default_n=1000000_\", \"camouflage\", \"tiny\",  \"less_variations_n=100000_\", \"less_variations_n=1000000_\"]\n",
    "models = [\"mlp\", \"conv4\", \"resnet18\", \"wrn\", \"vgg16\", \"warn\"]\n",
    "masks = [\"'random'\", \"'stratified_font'\", \"'stratified_char'\", \"'compositional_char_font'\", \"'stratified_scale'\", \"'stratified_rotation'\", \"'compositional_rotation_scale'\", \"'stratified_translation-x'\", \"'stratified_translation-y'\", \"'compositional_translation-x_translation-y'\"]\n",
    "tasks = [\"font\", \"char\"]\n",
    "\n",
    "def filter_dataset(dataframe, dset):\n",
    "    if dataset in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.name\"].str.contains(dset)]\n",
    "    else:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.path\"].str.contains(dset)]\n",
    "    return df_dataset\n",
    "def filter_task(dataframe, task):\n",
    "    if dataset not in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = dataframe[dataframe[\"dataset.task\"].str.contains(task)]\n",
    "    else:\n",
    "        df_dataset = dataframe\n",
    "    return df_dataset \n",
    "def filter_mask(dataframe, mask):\n",
    "    df_ood = dataframe[dataframe['dataset.mask'] == mask]\n",
    "    return df_ood\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    #     df_model = df[df[\"backbone.name\"].str.contains(model)]\n",
    "    df_dataset = filter_dataset(df, dataset)\n",
    "    for task in tasks:\n",
    "        df_task = filter_task(df_dataset, task)\n",
    "        for mask in masks:\n",
    "\n",
    "            if dataset not in [\"mnist\", \"svhn\"]:\n",
    "                df_ood = filter_mask(df_task, mask)\n",
    "            else:\n",
    "                df_ood = df_task\n",
    "                if task != \"char\" or mask != \"'random'\":\n",
    "                    continue\n",
    "            if len(df_ood) == 0:\n",
    "                continue\n",
    "            print(\"Dset:%s, Task:%s, MASK:%s\"% (dataset, task, mask))\n",
    "            for model in models:\n",
    "                df_model = df_ood[df_ood[\"backbone.name\"].str.contains(model)]\n",
    "                df_model = df_model.groupby('seed')[\"train_accuracy (max)\"].agg(np.nanmax).reset_index()\n",
    "                print(\"%.02f ±%.02f\" %(100*df_model[\"train_accuracy (max)\"].agg(np.nanmean), 100*df_model[\"train_accuracy (max)\"].agg(np.nanstd)))#, df_model[\"val_accuracy (max)\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny\n",
      "0.0018573602040608723\n",
      "0.0030656655629475913\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df = rm.get_score_df()\n",
    "\n",
    "datasets = [\"plain\", \"default_n=1000000_\", \"default_n=100000_\", \"mnist\", \"svhn\", \"tiny\"]\n",
    "datasets = [\"tiny\"]\n",
    "models = [\"mlp\", \"conv4\", \"resnet18\", \"resnet50\", \"vgg16\", \"warn\"]\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "#     df_model = df[df[\"backbone.name\"].str.contains(model)]\n",
    "    print(dataset)\n",
    "    if dataset in [\"mnist\", \"svhn\"]:\n",
    "        df_dataset = df[df[\"dataset.name\"].str.contains(dataset)]\n",
    "    else:\n",
    "        df_dataset = df[df[\"dataset.path\"].str.contains(dataset)]\n",
    "    for model in models:\n",
    "        df_model = df_dataset[df_dataset[\"backbone.name\"].str.contains(model)]\n",
    "        print(df_model[\"val_batch_time\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
